import csv
import time
import random
import ProcessOptimizer as po # used to suggest next experiment
from ProcessOptimizer.utils import cook_estimator #Used to customize the algorithm
from ProcessOptimizer.learning.gaussian_process.kernels import Matern #A specific "brain" in the algorithm
from ProcessOptimizer import expected_minimum
import glob
import os
import pandas as pd


Tecan_running_file = 'C:\\Users\\Tecan\\Desktop\\Variable.txt'
recipe_folder = 'C:\\Users\\Public\\Documents\\Tecan\\'
log_file = 'C:\\temp\\Trypsin_10buffers_n20_w_control_log_of_experimets.csv'
log_file_predictions='C:\\temp\\Trypsin_10buffers_n20_w_control_log_of_predictions.csv'
log_file_predictions_results='C:\\temp\\Trypsin_10buffers_n20_w_control_log_of_prediction_results.csv'
batch_size = 1
comparator_delta = 48
space = [(0, 10)]*10
n_objectives = 1
n_initial=20


def get_latest_file(path, fileextension):
    '''
    A function to open a path and find the newest file in the folder.
    If fileextension (e.g. 'csv') is given, then only specified files are
    searched
    Return: the absolute path to the newest file
    '''
    list_of_files = glob.glob(path + '**\\' + '*.' + fileextension, recursive=True)
    latest_file = max(list_of_files, key=os.path.getmtime)
    return latest_file

def humanize(well):
    """
    Inspired from: https://github.com/CyrusK/96-Well-Plate.py
    Given a number, return its human form
    """
    ROW = 8
    COL = 12

    # offset = (well-1)//(ROW)*i
    if well % ROW != 0:
        offset = well % ROW - 1
        colIndex = well // ROW + 1
    else:
        offset = ROW - 1
        colIndex = well // ROW

    rowIndex = chr(65 + offset)

    return rowIndex, str(colIndex)

def extract_SPARK_reading(experiment_number, latest_file, comparator_delta=None):
    '''
    A function to find, open and extract an absorbance reading from the latest
    experiment

    Parameters
    ----------
    experiment_number : Int
        Helps pinpoint position on plate to read number.
    comparator_delta : Int
        If given, we assume that a blank was run in a well. This well is assumed
        positioned as the experiment number + this given delta.
    latest_file : Str
        Absolute path to the result file.

    Returns
    -------
    Absorbance read in given well. If comparator is given, then blank reading
    is subtracted from reading

    '''

    df1 = pd.read_excel(latest_file)
    rowstoskip = df1[df1.iloc[:, 0] == "<>"].index.to_list()[0]
    footertoskip=int(df1.shape[0])-df1[df1.iloc[:,0] == "H"].index.to_list()[0]
    df = pd.read_excel(latest_file,
                       skiprows=int(rowstoskip)+1,
                       skipfooter=int(footertoskip)-1,
                       index_col='<>')
    sample_row, sample_column = humanize(experiment_number)
    absorbance_sample = df.loc[sample_row, str(sample_column)]
    if comparator_delta:
        blank_row, blank_column = humanize(experiment_number + comparator_delta)
        absorbance_blank = df.loc[blank_row, str(blank_column)]
        return absorbance_sample - absorbance_blank
    else:
        return absorbance_sample

def get_experiment_numbers(iteration, batch_size):
    '''
    Extracts a list of experiments

    Parameters
    ----------
    iteration : Int
        DESCRIPTION.
    batch_size : Ing
        DESCRIPTION.

    Returns
    -------
    A list of experiment numbers.

    '''
    start = (iteration - 1) * batch_size + 1
    stop = iteration * batch_size + 1
    return list(range(start, stop))

def read_tecan_status(link_to_control_file):
    with open(link_to_control_file) as file:
        line = file.readlines()[0]
    return line


def make_recipe_file(link_to_recipe_folder, iteration, recipe):
    next_x = recipe

    if batch_size == 1:
        recipe_file_first_add_falcon = os.path.join(link_to_recipe_folder, 'TRYPSIN_first_adds.csv')
        with open(recipe_file_first_add_falcon, mode='w', newline='') as file:
            writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
            if next_x[0] != 0:
                writer.writerow(['SOURCE4','1','DEST1', str(iteration), str(next_x[0])]) #Buf1
            if next_x[1] != 0:
                writer.writerow(['SOURCE4','2','DEST1', str(iteration), str(next_x[1])]) #Buf2
            if next_x[2] != 0:
                writer.writerow(['SOURCE4', '3', 'DEST1', str(iteration), str(next_x[2])])  # buf3
            if next_x[3] != 0:
                writer.writerow(['SOURCE4', '4', 'DEST1', str(iteration), str(next_x[3])])  # Buf4
            if next_x[4] != 0:
                writer.writerow(['SOURCE4', '5', 'DEST1', str(iteration), str(next_x[4])])  # Buf5
            if next_x[5] != 0:
                writer.writerow(['SOURCE4', '6', 'DEST1', str(iteration), str(next_x[5])])  # Buf6
            if next_x[6] != 0:
                writer.writerow(['SOURCE4', '7', 'DEST1', str(iteration), str(next_x[6])])  # Buf7
            if next_x[7] != 0:
                writer.writerow(['SOURCE4', '8', 'DEST1', str(iteration), str(next_x[7])])  # Buf8
            if next_x[8] != 0:
                writer.writerow(['SOURCE4', '9', 'DEST1', str(iteration), str(next_x[8])])  # Buf9
            if next_x[9] != 0:
                writer.writerow(['SOURCE4', '10', 'DEST1', str(iteration), str(next_x[9])])  # Buf10
            if next_x[0] != 0:
                writer.writerow(['SOURCE4','1','DEST1', str(iteration+comparator_delta), str(next_x[0])]) #Buf1
            if next_x[1] != 0:
                writer.writerow(['SOURCE4','2','DEST1', str(iteration+comparator_delta), str(next_x[1])]) #Buf2
            if next_x[2] != 0:
                writer.writerow(['SOURCE4', '3', 'DEST1', str(iteration+comparator_delta), str(next_x[2])])  # buf3
            if next_x[3] != 0:
                writer.writerow(['SOURCE4', '4', 'DEST1', str(iteration+comparator_delta), str(next_x[3])])  # Buf4
            if next_x[4] != 0:
                writer.writerow(['SOURCE4', '5', 'DEST1', str(iteration+comparator_delta), str(next_x[4])])  # Buf5
            if next_x[5] != 0:
                writer.writerow(['SOURCE4', '6', 'DEST1', str(iteration+comparator_delta), str(next_x[5])])  # Buf6
            if next_x[6] != 0:
                writer.writerow(['SOURCE4', '7', 'DEST1', str(iteration+comparator_delta), str(next_x[6])])  # Buf7
            if next_x[7] != 0:
                writer.writerow(['SOURCE4', '8', 'DEST1', str(iteration+comparator_delta), str(next_x[7])])  # Buf8
            if next_x[8] != 0:
                writer.writerow(['SOURCE4', '9', 'DEST1', str(iteration+comparator_delta), str(next_x[8])])  # Buf9
            if next_x[9] != 0:
                writer.writerow(['SOURCE4', '10', 'DEST1', str(iteration+comparator_delta), str(next_x[9])])  # Buf10
            writer.writerow(['SOURCE4','22','DEST1',str(iteration),str(100-(sum(next_x)))]) #Vol(water until 225uL)
            writer.writerow(['SOURCE4','23','DEST1',str(iteration),str(10)]) ##Add Trypsin solution until 10 ug/mL
            writer.writerow(['SOURCE4','24','DEST1',str(iteration),str(20)]) #Add substrate until 250uM
            #antal rækker tilsvarende antal komponenter i buffer
            writer.writerow(['SOURCE4','22','DEST1',str(iteration+comparator_delta),str(100-(sum(next_x))+10)]) #Vol(water until 225uL)
            writer.writerow(['SOURCE4','24','DEST1',str(iteration+comparator_delta),str(20)]) #Add substrate until 250uM



def make_log(link_to_log_file, iteration, latest_exp, list_of_transformed_meassurements):
    with open(link_to_log_file, mode='a', newline='') as file:
        writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)

        if iteration == 1:
            writer.writerow([str(i) for i in list(range(len(space) + n_objectives))])
        elif iteration > 1 and batch_size == 1:
            writer.writerow(latest_exp+list_of_transformed_meassurements)
        elif iteration > 1 and batch_size > 1:
            for i in range(batch_size):
                temp_list = latest_exp[i][:]
                temp_list.append(list_of_transformed_meassurements[i])
                writer.writerow(temp_list)
        else:
            print('Error # 42')



def make_log_predictions(link_to_log_file, iteration, latest_prediction, list_of_transformed_predictions):
    with open(link_to_log_file, mode='a', newline='') as file:
        writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
        
        if iteration > 1 and batch_size == 1:
            writer.writerow(latest_prediction+list_of_transformed_predictions)
        elif iteration > 1 and batch_size > 1:
            for i in range(batch_size):
                temp_list = latest_prediction[i][:]
                temp_list.append(list_of_transformed_predictions[i])
                writer.writerow(temp_list)
        else:
            print('Error # 42')

def update_tecan_status(link_to_control_file, status):
    with open(link_to_control_file, 'w') as file:
        file.write(str(status))

def make_optimizer():
    space = [(0, 10)]*10 #(0,10) x antal solvent
    lhs = True
    n_objectives = 1
    kernel_intern = 1 ** 2 * Matern(length_scale=[1]*10, length_scale_bounds=[(0.05, 10)], nu=2.5)
    base_est = cook_estimator(base_estimator='GP', space=space, normalize_y=True, noise='gaussian',
                              kernel=kernel_intern)
    # Instantiate the optimizer, we are building:
    optimizer = po.Optimizer(dimensions=space,
                                  acq_func='EI',
                                  n_initial_points=n_initial,
                                  lhs=lhs,
                                  n_objectives=n_objectives,
                                  base_estimator=base_est,
                                  acq_func_kwargs={'xi': 0.1})
    return optimizer

def make_recipe_csv(link,result_column,header=None,every_n=5):
    df = pd.read_csv(link, sep=',',header=header)
    df.drop(result_column,axis=1,inplace=True)
    df_sub=df[[i%every_n==0 for i in range(len(df))]]
    return df_sub
    
def make_recipe_file(link_to_recipe_folder, iteration, ammount_of_buffers, source_name,destination_name,comparator_delta, recipe):
    next_x = recipe

    recipe_file_first_add_falcon = os.path.join(link_to_recipe_folder, 'TRYPSIN_test_predictions.csv')
    with open(recipe_file_first_add_falcon, mode='a', newline='') as file:
        writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
        
        for i in range(ammount_of_buffers):
            if next_x[i] != 0:
                writer.writerow([source_name,str(i+1),destination_name, str(iteration), str(next_x[i])]) #Buf1
        if comparator_delta:        
            for i in range(ammount_of_buffers):
                if next_x[i] != 0:
                    writer.writerow([source_name,str(i+1),destination_name, str(iteration+comparator_delta), str(next_x[i])]) #Buf1-10
        writer.writerow([source_name,22,destination_name,str(iteration),str(100-(sum(next_x)))]) #Vol(water until 225uL)
        #writer.writerow([source_name,23,destination_name,str(iteration),str(10)]) ##Add Trypsin solution until 10 ug/mL
        writer.writerow([source_name,24,destination_name,str(iteration),str(20)]) #Add substrate until 250uM
        #antal rækker tilsvarende antal komponenter i buffer
        if comparator_delta:
            writer.writerow([source_name,22,destination_name,str(iteration+comparator_delta),str(100-(sum(next_x))+10)]) #Vol(water until 225uL)
            writer.writerow([source_name,24,destination_name,str(iteration+comparator_delta),str(20)]) #Add substrate until 250uM


def make_full_recipy(link,result_column,link_to_recipe_folder,header,ammount_of_buffers,source_name,comparator_delta,destination_name,every_n=5):
    df1=make_recipe_csv(link,result_column,header,every_n)

    for i in range(len(df1)):
        recipe=df1.values.tolist()[i]
        make_recipe_file(link_to_recipe_folder=link_to_recipe_folder,
                         iteration=i+1,
                         ammount_of_buffers=ammount_of_buffers,
                         source_name=source_name,
                         comparator_delta=comparator_delta,
                         destination_name=destination_name,
                         recipe=recipe)
        
    recipe_file_first_add_falcon = os.path.join(link_to_recipe_folder, 'TRYPSIN_test_predictions.csv')
    with open(recipe_file_first_add_falcon, mode='a', newline='') as file:
        writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
        
        for i in range(len(df1)):
            writer.writerow([source_name,23,destination_name,str(i+1),str(10)]) ##Add Trypsin solution until 10 ug/mL
            
def make_log_predictions_results(log_file_predictions_results,log_file_predictions,excel_output):
    df_predictions = pd.read_csv(log_file_predictions, sep=',',header=None)
    
    df=excel_output
    with open(log_file_predictions_results, mode='a', newline='') as file:
        writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
        for i in range(len(df_predictions)):
            sample_row, sample_column = humanize(i+1)
            absorbance_sample = df.loc[sample_row, str(sample_column)]
            blank_row, blank_column = humanize(i +1+ comparator_delta)
            absorbance_blank = df.loc[blank_row, str(blank_column)]
            writer.writerow(["Model expected",str(df_predictions.iloc[i,10]),"Experiment gave",str(absorbance_sample - absorbance_blank)])
            

update_tecan_status(Tecan_running_file, '"standby"')


iteration = 0



for i in range(100000):

    tecan_running = read_tecan_status(Tecan_running_file)

    print(f'Read Status of tecan_running-file. it is {tecan_running} and of type {type(tecan_running)}')
    if tecan_running == '"running"':
        time.sleep(60)
        print('tecan must still be running. I\'ll keep waiting')
    elif tecan_running[:9] == '"standby"':
        print(f'tecan is done running, now it\'s my turn')
        if iteration == 0:
            iteration = 1
            print(f'Running on iteration {iteration}')
            well_numbers = get_experiment_numbers(iteration, batch_size)
            print(f'Just found wellnumbers to be {well_numbers}')

            opt = make_optimizer()
            next_x = opt.ask(batch_size)

            make_recipe_file(recipe_folder, iteration, next_x)

            update_tecan_status(Tecan_running_file, '"running"')
            time.sleep(5)

        else:
            old_well_numbers = get_experiment_numbers(iteration, batch_size)
            latest_file = get_latest_file('C:\\Users\\Public\\Documents\\Tecan\\SparkControl\\Workspaces\\',
                                               'xlsx')
            list_of_meassurements = [
                extract_SPARK_reading(well_number, latest_file, comparator_delta=comparator_delta) for
                well_number in old_well_numbers]
            list_of_transformed_meassurements = [1 - float(meassurement) for meassurement in list_of_meassurements]
            temporary_model=opt.tell([latest_exp], list_of_transformed_meassurements)
            
            next_x = opt.ask(batch_size)
            if iteration >= n_initial:
                prediction=expected_minimum(temporary_model)
                x_prediction=prediction[0]
                y_prediction=[prediction[1]]
                make_log_predictions(log_file_predictions,iteration,x_prediction,y_prediction)
            iteration += 1
            print(f'Running on iteration {iteration}, because we have {len(opt.Xi)} datas')
            well_numbers = get_experiment_numbers(iteration, batch_size)
            print(f'Just found wellnumbers to be {well_numbers}')
            make_log(log_file, iteration, latest_exp, list_of_transformed_meassurements)

                
            make_recipe_file(recipe_folder, iteration, next_x)

            update_tecan_status(Tecan_running_file, '"running"')
            time.sleep(5)

        latest_exp = next_x[:]

    elif tecan_running[:7] == '"final"':
        print('Finished')
        time.sleep(5)
        break
    else:
        print(f'tecan_running was {tecan_running}, I had expected it to be in [0,1]')


#ammount_of_buffers=10
#source_name="SOURCE4"
#destination_name="DEST2"
#comparator_delta=48
#every_n=1
#link_to_recipe_folder=recipe_folder

make_full_recipy(link=log_file_predictions,
                 result_column=10,
                 link_to_recipe_folder=recipe_folder,
                 header=None,
                 ammount_of_buffers=10,
                 source_name="SOURCE4",
                 comparator_delta=48,
                 destination_name="DEST2",
                 every_n=1)
                 
update_tecan_status(Tecan_running_file, '"running"')
print("switching to testing predictions")

for i in range(10000):
    tecan_running = read_tecan_status(Tecan_running_file)
    print(f'Read Status of tecan_running-file. it is {tecan_running} and of type {type(tecan_running)}')
    if tecan_running == '"running"':
        time.sleep(60)
        print('tecan must still be running (trying predictions). I\'ll keep waiting')
    elif tecan_running[:9] == '"standby"':
        latest_file=get_latest_file('C:\\Users\\Public\\Documents\\Tecan\\SparkControl\\Workspaces\\','xlsx')
        df1 = pd.read_excel(latest_file)
        rowstoskip = df1[df1.iloc[:, 0] == "<>"].index.to_list()[0]
        footertoskip=int(df1.shape[0])-df1[df1.iloc[:,0] == "H"].index.to_list()[0]
        
        excel_output = pd.read_excel(latest_file,
                           skiprows=int(rowstoskip)+1,
                           skipfooter=int(footertoskip)-1,
                           index_col='<>')
        make_log_predictions_results(log_file_predictions_results=log_file_predictions_results,log_file_predictions=log_file_predictions,excel_output=excel_output)
        print("all done")
        break 
